{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Luther: Web Scraping and Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will be analyzing data on student and teacher demographics and see if there seems to be any kind of relationship between Illinois teacher demographics and the \"achievement gap\" between hispanic students and their white peers on standardized math tests in high school (The PSAE).\n",
    "\n",
    "This notebook contains the code to scrape the publicly available data from the Illinois Report Card website and convert it to a pandas dataframe object\n",
    "\n",
    "URL: https://www.illinoisreportcard.com/ListSchools.aspx\n",
    "\n",
    "Analysis will be covered in a second notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initializing libraries and modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium Data Scraping Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I decided to use Selenium as my weapon of choice to scrape data because the Illinois Report Card Website has dynamic content that requires quite a bit of clicking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is just a few values and a function to keep track of scraping progress so that data collection can be smootly resumed if there is an interruption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below opens up a new chrome window from where all the data will be collected. The data collection will be automated through Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_alpha_index = 0\n",
    "current_item_index = 0\n",
    "current_school_name= \"N/A (No Data collected yet)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def current_scrape_progress():\n",
    "    print(f\"The last school encountered was: {current_school_name}\")\n",
    "    print(f\"Next Alphabetical Index value to check: {current_alpha_index}\")\n",
    "    print(f\"Next school index on that page is: {current_item_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping will yield unique dictionaries for each school containing scraped data. All of these dictionaries will be contained within a **master_list_school_dictionaries** variable until data collection is complete.\n",
    "Once all the scraping is complete, the list of dictionaries will be converted into a pandas dataframe object.\n",
    "The **valid_district_counties_master_dictionary** holds a all the school districts present in the data set as keys and associated Counties as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_list_school_dictionaries = []\n",
    "valid_district_counties_master_dictionary = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following five functions will contain the means to navigate the website to collect data on each high school. The high schools are organized by alphabet on separate webpages for each alphabet.\n",
    "\n",
    "- The function **data_scraper_wrapper** is just a wrapper around the next four main scraping functions\n",
    "\n",
    "- Running the **page_navigator** will set the entire data scraping apparatus into motion. It will start at the first webpage with school names beginning with 'A' navigate to the next webpage after all the high school links on the current page have been sorted through and will end at the alphabet 'Z'.\n",
    "- The **link_navigator** will cycle through all the high school school links on the current webpage.\n",
    "    - The **is_highschool** helper function returns a boolean to assist the link_navigator in differentiating high schools from elementary/middle schools.\n",
    "\n",
    "\n",
    "- The **open_school_in_new_tab** function opens the school link in a new tab when the link_navigator has selected a high school. It runs the grab_student_data function on the new tab to collect student data. After data collection for the school has been completed, open_school_in_new_tab closes the tab and returns focus to the main window containing all the school links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_scraper_wrapper(driver,\n",
    "                         starting_alpha_index=current_alpha_index,\n",
    "                         starting_item_index=current_item_index):\n",
    "    time.sleep(1)\n",
    "    current_scrape_progress()\n",
    "    page_navigator(driver,starting_alpha_index,starting_item_index)\n",
    "    print(f\"Scrape Completed. Total schools in data set = {len(master_list_school_dictionaries)}\")\n",
    "\n",
    "\n",
    "def page_navigator(driver,\n",
    "                   starting_alpha_index=current_alpha_index,\n",
    "                   starting_item_index=current_item_index):\n",
    "    \"\"\"\n",
    "    will navigate pages by alphabetical-navigation while scraping data about every high school\n",
    "    \"\"\"\n",
    "    global current_alpha_index\n",
    "    global current_item_index\n",
    "    \n",
    "    driver.switch_to_default_content()\n",
    "    alpha_page_nav_list = driver.find_elements_by_xpath(\"//div[contains(@class,'pagination')]//a\")\n",
    "    alpha_page_index =  starting_alpha_index\n",
    "    working_school_index = starting_item_index\n",
    "    \n",
    "    while alpha_page_index < len(alpha_page_nav_list):\n",
    "        # the need to redefine alpha_page_nav_list is because of all the scraping done, this list of stored\n",
    "        # elements is now \"stale\" and no longer in memory\n",
    "        alpha_page_nav_list = driver.find_elements_by_xpath(\"//div[contains(@class,'pagination')]//a\")\n",
    "        if alpha_page_index >0:\n",
    "            moveto_page=alpha_page_nav_list[alpha_page_index]\n",
    "            moveto_page.send_keys(\"\\n\")\n",
    "        link_navigator(driver,working_school_index)\n",
    "        print(f'Just completed Alpha_index {alpha_page_index}!!!')\n",
    "        alpha_page_index +=1\n",
    "        current_alpha_index = alpha_page_index\n",
    "        current_item_index = 0\n",
    "        working_school_index = current_item_index\n",
    "        \n",
    "\n",
    "def link_navigator(driver,\n",
    "                  starting_item_index=current_item_index):\n",
    "    \"\"\"\n",
    "    For the school links on the alpha-nav sorted page, this function\n",
    "    will append scraped data about every high school to\n",
    "    master_list_of_school_dictionaries\n",
    "    \"\"\"\n",
    "    global current_item_index\n",
    "    global current_school_name\n",
    "    \n",
    "    # Generate school list for schools remaining on page\n",
    "    xpath_schools = \"//div[contains(@class,'cellLeft')]//a\"\n",
    "    school_elements = driver.find_elements_by_xpath(xpath_schools)\n",
    "    total_schools_on_page = len(school_elements)\n",
    "    school_elements = school_elements[starting_item_index:]\n",
    "    # Generate the associated school type for schools remaining on page\n",
    "    xpath_school_type = \"//div[a and contains(@class,'cellLeft')]\"\n",
    "    school_type_elements = driver.find_elements_by_xpath(xpath_school_type)\n",
    "    school_type_elements = school_type_elements[starting_item_index:]\n",
    "    # Generate Districts and counties for remaining schools on page\n",
    "    xpath_districts = \"//div[div[contains(@class,'cellLeft')]//a]/div[contains(@class,'4')]\"\n",
    "    district_county_elements = driver.find_elements_by_xpath(xpath_districts)\n",
    "    district_county_elements = [element.text for element in district_county_elements]\n",
    "    district_county_elements = district_county_elements[starting_item_index:]\n",
    "    #want to only select high schools\n",
    "    for school_link,school_type_el,district_county_el in zip(school_elements,school_type_elements,district_county_elements):\n",
    "        current_school_name = school_link.text\n",
    "        school_type = school_type_el.text\n",
    "        if is_highschool(school_type):\n",
    "            school_data_dict = open_school_in_new_tab(school_link,driver)\n",
    "            if school_data_dict is not None:\n",
    "                school_data_dict['school_name'] = current_school_name\n",
    "                dist_county_info = obtain_district_and_county(district_county_el)\n",
    "                school_data_dict.update(dist_county_info)\n",
    "                master_list_school_dictionaries.append(school_data_dict)\n",
    "                if len(master_list_school_dictionaries) % 20 == 0:\n",
    "                    print(f\"Our master list now has data on {len(master_list_school_dictionaries)} schools\")                    \n",
    "        if (current_item_index + 1) % 30 == 0:\n",
    "            print(f\"Just passed school {current_item_index + 1} ({current_school_name}) of {total_schools_on_page} schools; only {total_schools_on_page - current_item_index -1} to go!\")\n",
    "        current_item_index += 1\n",
    "        \n",
    "def is_highschool(school_type):\n",
    "    \"\"\"\n",
    "    Based on description on site, checks to see if a given school is a high school\n",
    "    if it is a high school, returns true. if not a high school, returns false.\n",
    "    \"\"\"\n",
    "    it_is_a_highschool = False\n",
    "    regex = re.compile('-12',re.DOTALL|re.MULTILINE)\n",
    "    is_a_highschool_query = re.search(regex,school_type)\n",
    "    if is_a_highschool_query:\n",
    "        it_is_a_highschool = True    \n",
    "    return it_is_a_highschool\n",
    "\n",
    "def obtain_district_and_county(district_county_raw_text):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with the district and county of current school element\n",
    "    \"\"\"\n",
    "    district_county_dict = {}\n",
    "    district_regex = re.compile('(.*)\\n')\n",
    "    district = re.findall(district_regex,district_county_raw_text)[0]\n",
    "    district_county_dict['school_district'] = district\n",
    "    if district not in valid_district_counties_master_dictionary.keys():\n",
    "        county_regex = re.compile('\\n\\s*\\((.*)\\)')\n",
    "        county = re.findall(county_regex,district_county_raw_text)[0]\n",
    "        district_county_dict['school_county'] = county\n",
    "    else:\n",
    "        district_county_dict['school_county'] = valid_district_counties_master_dictionary[district]\n",
    "    return district_county_dict\n",
    "\n",
    "def open_school_in_new_tab(school_link,driver):\n",
    "    \"\"\"\n",
    "    opens the school link in a new tab, runs data scraping algorithm,\n",
    "    closes the tab, returns the data for the school as a dictionary,\n",
    "    and then switches window focus back to the list of schools\n",
    "    \"\"\"\n",
    "    main_window=driver.current_window_handle\n",
    "    #open the school in a new tab\n",
    "    school_link.send_keys(Keys.CONTROL + Keys.RETURN)\n",
    "    #switch to the new tab\n",
    "    driver.switch_to_window(driver.window_handles[-1])\n",
    "    #collect the school data\n",
    "    driver.switch_to_default_content()\n",
    "    school_data_dict = grab_school_data(driver)\n",
    "    #close the tab and switch focus to the original school list\n",
    "    driver.close()\n",
    "    driver.switch_to_window(main_window)\n",
    "    driver.switch_to_default_content()\n",
    "    return school_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following five functions are responsible for extracting the data from each school.\n",
    "For each school, a dictionary will be returned containing:\n",
    "\n",
    "*{School Name, White Hispanic achievement gap, white student demographics, black student demographics, hispanic student demographics, white teacher demographics, black teacher demographics, and hispanic teacher demographics}*\n",
    "\n",
    "- The **grab_school_data** function is the main wrapper for executing the smaller functions. If the *hispanic-white achivement gap* value is not present for a particular school, the function will stop collecting data for that school and return a value of *None* to the open_school_in_new_tab function which originall called grab_school_data.\n",
    "- **grab_achievement_gap** is the gatekeeper. If a grab_achievement_gap value cannot be obtained, there is no point in collecting any more data for the school since the achievement gap **is my output variable of interest**.\n",
    "- **grab_school_name**, **grab_student_ethnicity**, **grab_teacher_ethnicity** are self explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_school_data(driver):\n",
    "    \"\"\"\n",
    "    runs a scraping script for a specific school and returns\n",
    "    a dictionary containing desired data in key:value form\n",
    "    \"\"\"\n",
    "    # Sometimes a school's link may be broken. Let's guard against that by seeking the presence of a left navbar\n",
    "    nav_bar_xpath = \"//ul[@id='leftNavTabs']/li/a\"\n",
    "    nav_bar = driver.find_elements_by_xpath(nav_bar_xpath)\n",
    "    if len(nav_bar) == 0:\n",
    "        error_xpath = \"//div[contains(@class,'alert') and contains(text(),'not available')]\"\n",
    "        error_message = driver.find_elements_by_xpath(error_xpath)\n",
    "        if len(error_message) > 0:\n",
    "            return None\n",
    "    # Onto the main function if the link checks out\n",
    "    school_data_dict = {}\n",
    "    hw_achievement_gap = grab_hw_achievement_gap(driver)\n",
    "    if hw_achievement_gap != {}:\n",
    "        other_achievement_gaps = grab_other_achievement_gaps(driver)\n",
    "        student_enrollment = grab_student_enrollment(driver)\n",
    "        student_demographics = grab_student_ethnicity(driver)\n",
    "        district_teacher_demographics = grab_teacher_ethnicity(driver)\n",
    "        school_data_dict.update(hw_achievement_gap)\n",
    "        school_data_dict.update(other_achievement_gaps)\n",
    "        school_data_dict.update(student_enrollment)\n",
    "        school_data_dict.update(student_demographics)\n",
    "        school_data_dict.update(district_teacher_demographics)\n",
    "        return school_data_dict\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def grab_hw_achievement_gap(driver):    \n",
    "    \"\"\"\n",
    "    checks to see if data for the school includes a\n",
    "    white-hispanic standardized test score achievement gap\n",
    "    if it does, this will return the value of the gap as a dictionary.\n",
    "    \"\"\"\n",
    "    hw_achievement_gap = {}\n",
    "    academic_info_xpath = \"//ul[@id='leftNavTabs']/li/a[text()='Academic Progress']\"\n",
    "    academic_info = driver.find_element_by_xpath(academic_info_xpath)\n",
    "    academic_info.send_keys(\"\\n\")\n",
    "    #Clicking on the Achievement Gap Tab\n",
    "    achievement_gap_xpath = \"//ul[@id='leftNavTabs']/li[a[text()='Academic Progress']]//a[text()='Achievement Gap']\"\n",
    "    achievement_gap = driver.find_element_by_xpath(achievement_gap_xpath)\n",
    "    achievement_gap.send_keys(\"\\n\")\n",
    "    #Selecting SAT scores (not PARCC)\n",
    "    sat_select_xpath = \"//ul[@class='pagination']//a[contains(text(),'SAT')]\"\n",
    "    sat_select = driver.find_element_by_xpath(sat_select_xpath)\n",
    "    sat_select.send_keys(\"\\n\")\n",
    "    time.sleep(5)\n",
    "    # Entering the IFrame\n",
    "    iframe_xpath = \"//iframe[@id='IFrame_IRC']\"\n",
    "    driver.switch_to_frame(driver.find_element_by_xpath(iframe_xpath))\n",
    "    # Clicking options\n",
    "    poverty_checkbox_xpath = \"//input[contains(@id,'Income')]\"\n",
    "    hisp_white_checkbox_xpath = \"//input[contains(@id,'Hispanic,White')]\"\n",
    "    math_checkbox_xpath = \"//label[@data-code='Mathematics']/input\"\n",
    "    results_xpath = \"//div[@class='result']\"\n",
    "    unclick_poverty = driver.find_element_by_xpath(poverty_checkbox_xpath)\n",
    "    unclick_poverty.send_keys(Keys.SPACE)\n",
    "    click_hisp_white_gap = driver.find_element_by_xpath(hisp_white_checkbox_xpath)\n",
    "    click_hisp_white_gap.send_keys(Keys.SPACE)\n",
    "    click_math = driver.find_element_by_xpath(math_checkbox_xpath)\n",
    "    click_math.send_keys(Keys.SPACE)\n",
    "    Hisp_White_Achievement_Gap = driver.find_element_by_xpath(results_xpath)\n",
    "    Hisp_White_Achievement_Gap = Hisp_White_Achievement_Gap.text\n",
    "    regex = re.compile('Hispanic and White\\n(.?[0-9]+)\\n',re.IGNORECASE|re.DOTALL)\n",
    "    if re.search(regex,Hisp_White_Achievement_Gap):\n",
    "        Hisp_White_Achievement_Gap_Value = float(re.findall(regex,Hisp_White_Achievement_Gap)[0])\n",
    "        hw_achievement_gap['Hispanic_White_Achievement_Gap']=Hisp_White_Achievement_Gap_Value\n",
    "    driver.switch_to_default_content()\n",
    "    return hw_achievement_gap\n",
    "    \n",
    "def grab_other_achievement_gaps(driver):    \n",
    "    \"\"\"\n",
    "    checks to see if data for the school includes a\n",
    "    white-hispanic standardized test score achievement gap\n",
    "    if it does, this will return the value of the gap.\n",
    "    \"\"\"\n",
    "    other_achievement_gaps = {}\n",
    "    #Should already be on the achievement gap , SAT section of the Academic Progress Tab\n",
    "    #from the grab_hw_achievement_gap function\n",
    "    # Re-entering the IFrame\n",
    "    iframe_xpath = \"//iframe[@id='IFrame_IRC']\"\n",
    "    driver.switch_to_frame(driver.find_element_by_xpath(iframe_xpath))\n",
    "    # Extracting Black - White Achievement Gap\n",
    "    hisp_white_checkbox_xpath = \"//input[contains(@id,'Hispanic,White')]\"\n",
    "    blk_white_checkbox_xpath = \"//input[contains(@id,'Black,White')]\"\n",
    "    blk_hisp_checkbox_xpath = \"//input[contains(@id,'Black,Hispanic')]\"\n",
    "    results_xpath = \"//div[@class='result']\"\n",
    "    unclick_hisp_white_gap = driver.find_element_by_xpath(hisp_white_checkbox_xpath)\n",
    "    unclick_hisp_white_gap.send_keys(Keys.SPACE)\n",
    "    click_blk_white_gap = driver.find_element_by_xpath(blk_white_checkbox_xpath)\n",
    "    click_blk_white_gap.send_keys(Keys.SPACE)\n",
    "    Blk_White_Achievement_Gap = driver.find_element_by_xpath(results_xpath)\n",
    "    Blk_White_Achievement_Gap = Blk_White_Achievement_Gap.text\n",
    "    regex = re.compile('Black and White\\n(.?[0-9]+)\\n',re.IGNORECASE|re.DOTALL)\n",
    "    if re.search(regex,Blk_White_Achievement_Gap):\n",
    "        Blk_White_Achievement_Gap_Value = float(re.findall(regex,Blk_White_Achievement_Gap)[0])\n",
    "        other_achievement_gaps['Black_White_Achievement_Gap'] = Blk_White_Achievement_Gap_Value\n",
    "    # Extracting Black - Hispanic Achievement Gap\n",
    "    unclick_blk_white_gap = click_blk_white_gap # Just re-selecting the above checkbox element to un-click it\n",
    "    unclick_blk_white_gap.send_keys(Keys.SPACE)\n",
    "    click_blk_hisp_gap = driver.find_element_by_xpath(blk_hisp_checkbox_xpath)\n",
    "    click_blk_hisp_gap.send_keys(Keys.SPACE)\n",
    "    Blk_Hisp_Achievement_Gap = driver.find_element_by_xpath(results_xpath)\n",
    "    Blk_Hisp_Achievement_Gap = Blk_Hisp_Achievement_Gap.text\n",
    "    regex = re.compile('Black and Hispanic\\n(.?[0-9]+)\\n',re.IGNORECASE|re.DOTALL)\n",
    "    if re.search(regex,Blk_Hisp_Achievement_Gap):\n",
    "        Blk_Hisp_Achievement_Gap_Value = float(re.findall(regex,Blk_Hisp_Achievement_Gap)[0])\n",
    "        other_achievement_gaps['Black_Hispanic_Achievement_Gap'] = Blk_Hisp_Achievement_Gap_Value\n",
    "    driver.switch_to_default_content()\n",
    "    return other_achievement_gaps\n",
    "\n",
    "\n",
    "def grab_student_enrollment(driver):\n",
    "    \"\"\"\n",
    "    returns student enrollment as a dictionary\n",
    "    \"\"\"\n",
    "    student_enrollment_dict = {}\n",
    "    students_info_xpath = \"//ul[@id='leftNavTabs']/li/a[text()='Students']\"\n",
    "    students_info = driver.find_element_by_xpath(students_info_xpath)\n",
    "    students_info.send_keys(\"\\n\")\n",
    "    student_enrollment_xpath = \"//ul[@id='leftNavTabs']/li[a[text()='Students']]//a[text()='Enrollment']\"\n",
    "    student_enrollment_el = driver.find_element_by_xpath(student_enrollment_xpath)\n",
    "    student_enrollment_el.send_keys(\"\\n\")\n",
    "    time.sleep(5)\n",
    "    # Entering IFrame\n",
    "    iframe_xpath = \"//iframe[@id='IFrame_IRC']\"\n",
    "    driver.switch_to_frame(driver.find_element_by_xpath(iframe_xpath))\n",
    "    enrollment_val_xpath = \"//div[contains(@class,'grid-cell')][last()]\"\n",
    "    enrollment_val_el = driver.find_element_by_xpath(enrollment_val_xpath)\n",
    "    enrollment_val = enrollment_val_el.text\n",
    "    student_enrollment_dict['student_enrollment'] = int(float(enrollment_val.replace(',','')))\n",
    "    driver.switch_to_default_content()\n",
    "    return student_enrollment_dict\n",
    "\n",
    "def grab_student_ethnicity(driver):\n",
    "    \"\"\"\n",
    "    returns black, white, and hispanic student demographics as a dictionary\n",
    "    \"\"\"\n",
    "    # Should already have Students Tab selected from the left navbar\n",
    "    student_demographics = {}\n",
    "    student_ethnicity_el = driver.find_element_by_xpath(\"//ul[@id='leftNavTabs']/li[a[text()='Students']]//a[text()='Racial/Ethnic Diversity']\")\n",
    "    student_ethnicity_el.send_keys(\"\\n\")\n",
    "    time.sleep(5)\n",
    "    # Entering IFrame\n",
    "    iframe_xpath = \"//iframe[@id='IFrame_IRC']\"\n",
    "    driver.switch_to_frame(driver.find_element_by_xpath(iframe_xpath))\n",
    "    graph_info_xpath = \"//div[@id='graph-data']\"\n",
    "    graph_info = driver.find_element_by_xpath(graph_info_xpath)\n",
    "    graph_info_text = graph_info.text\n",
    "    regex = re.compile('White \\(([0-9]+\\.?[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    student_demographics['white_students'] = float(re.findall(regex,graph_info_text)[0])\n",
    "    regex = re.compile('Black \\(([0-9]+\\.?[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    student_demographics['black_students'] = float(re.findall(regex,graph_info_text)[0])   \n",
    "    regex = re.compile('Hispanic \\(([0-9]+\\.?[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    student_demographics['hispanic_students'] = float(re.findall(regex,graph_info_text)[0])\n",
    "    driver.switch_to_default_content()\n",
    "    return student_demographics\n",
    "    \n",
    "\n",
    "def grab_teacher_ethnicity(driver):\n",
    "    \"\"\"\n",
    "    returns black, white, and hispanic teacher demographics as a dictionary\n",
    "    \"\"\"\n",
    "    teacher_demographics = {}\n",
    "    teacher_info_xpath = \"//ul[@id='leftNavTabs']/li/a[text()='Teachers']\"\n",
    "    teachers_info = driver.find_element_by_xpath(teacher_info_xpath)\n",
    "    teachers_info.send_keys('\\n')\n",
    "    teacher_dems_xpath = \"//ul[@id='leftNavTabs']/li[a[text()='Teachers']]//a[text()='Demographics']\"\n",
    "    teacher_dems_el = driver.find_element_by_xpath(teacher_dems_xpath)\n",
    "    teacher_dems_el.send_keys('\\n')\n",
    "    time.sleep(7)\n",
    "    # Entering IFrame\n",
    "    iframe_xpath = \"//iframe[@id='IFrame_IRC']\"\n",
    "    driver.switch_to_frame(driver.find_element_by_xpath(iframe_xpath))\n",
    "    # Extracting teacher demographics\n",
    "    graph_info_xpath = \"//div[@id='nested-graph']\"\n",
    "    graph_info = driver.find_element_by_xpath(graph_info_xpath)\n",
    "    graph_info_text = graph_info.text\n",
    "    regex = re.compile('White \\(([0-9]+\\.?[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    temp_re = re.findall(regex,graph_info_text)\n",
    "    teacher_demographics['Dist_white_teachers'] = float(temp_re[0])\n",
    "    regex = re.compile('Black \\(([0-9]+\\.?[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    temp_re = re.findall(regex,graph_info_text)\n",
    "    teacher_demographics['Dist_black_teachers'] = float(temp_re[0])   \n",
    "    regex = re.compile('Hispanic \\(([0-9]+\\.?[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    temp_re = re.findall(regex,graph_info_text)\n",
    "    teacher_demographics['Dist_hispanic_teachers'] = float(temp_re[0])\n",
    "    driver.switch_to_default_content()\n",
    "    return teacher_demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape the data, all that needs to be done is run the **page_navigator**. All data will be collected within list element *master_list_of_school_dictionaries*.\n",
    "\n",
    "Caution: A nasty NoSuchElementFound Error will occur if your internet connection is too slow to load the dynamic javascript based webpage content before the script searches for certain elements. A fix for this would be:\n",
    "\n",
    "a. to add/increase time.sleep() times in certain parts of the script. This is bad practice, hacky, and non-pythonic. Unfortunately, it is needed sometimes because IFrames are weird.\n",
    "\n",
    "b. Better method: use the WebDriverWait function in conjunction with the expected_conditions module from the appropriate Selenium packages which will wait until an element is loaded for a user-specified time before python throws an error.\n",
    "    - This is considered best practice.\n",
    "    - time.sleep() works but is not best practice (allegedly).\n",
    "    \n",
    "c. My preferred method: Use implicit waits that instructs the Webdriver to search for an element repeatedly for a set period of time (I choose 12 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last school encountered was: ADLAI E STEVENSON HIGH SCHOOL\n",
      "Next Alphabetical Index value to check: 0\n",
      "Next school index on that page is: 43\n"
     ]
    }
   ],
   "source": [
    "current_scrape_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the next cell is all that is needed to collect the data. If the data collection is interrupted, just re-run this cell and the collection process will continue where it left of.\n",
    "\n",
    "Note: My data collection is complete. Script took around 5+ hours to run not including interrruptions. I have included long hard-coded sleeps/waits at points in the data collection functions to account for elements sometimes taking too long to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chromedriver_path = \"/home/farhaan/chromedriver\"\n",
    "chrome_driver = webdriver.Chrome(chromedriver_path)\n",
    "chrome_driver.implicitly_wait(12)\n",
    "chrome_driver.get('https://www.illinoisreportcard.com/ListSchools.aspx')\n",
    "data_scraper_wrapper(chrome_driver,current_alpha_index,current_item_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Black_Hispanic_Achievement_Gap': nan,\n",
       "  'Black_White_Achievement_Gap': nan,\n",
       "  'Dist_black_teachers': 0.2,\n",
       "  'Dist_hispanic_teachers': 8.3,\n",
       "  'Dist_white_teachers': 88.7,\n",
       "  'Hispanic_White_Achievement_Gap': -15.0,\n",
       "  'black_students': 0.7,\n",
       "  'hispanic_students': 32.2,\n",
       "  'school_county': 'MCHENRY',\n",
       "  'school_district': 'WOODSTOCK CUSD 200',\n",
       "  'school_name': 'WOODSTOCK NORTH HIGH SCHOOL',\n",
       "  'student_enrollment': 942,\n",
       "  'white_students': 62.6},\n",
       " {'Black_Hispanic_Achievement_Gap': -30.0,\n",
       "  'Black_White_Achievement_Gap': -57.0,\n",
       "  'Dist_black_teachers': 0.4,\n",
       "  'Dist_hispanic_teachers': 4.4,\n",
       "  'Dist_white_teachers': 92.4,\n",
       "  'Hispanic_White_Achievement_Gap': -27.0,\n",
       "  'black_students': 3.3,\n",
       "  'hispanic_students': 13.7,\n",
       "  'school_county': 'DUPAGE',\n",
       "  'school_district': 'ELMHURST SD 205',\n",
       "  'school_name': 'YORK COMM HIGH SCHOOL',\n",
       "  'student_enrollment': 2732,\n",
       "  'white_students': 75.2},\n",
       " {'Black_Hispanic_Achievement_Gap': -5.0,\n",
       "  'Black_White_Achievement_Gap': -27.0,\n",
       "  'Dist_black_teachers': 1.0,\n",
       "  'Dist_hispanic_teachers': 2.2,\n",
       "  'Dist_white_teachers': 95.7,\n",
       "  'Hispanic_White_Achievement_Gap': -21.0,\n",
       "  'black_students': 5.8,\n",
       "  'hispanic_students': 17.1,\n",
       "  'school_county': 'KENDALL',\n",
       "  'school_district': 'YORKVILLE CUSD 115',\n",
       "  'school_name': 'YORKVILLE HIGH SCHOOL',\n",
       "  'student_enrollment': 1746,\n",
       "  'white_students': 70.5},\n",
       " {'Black_Hispanic_Achievement_Gap': -10.0,\n",
       "  'Black_White_Achievement_Gap': -19.0,\n",
       "  'Dist_black_teachers': 21.5,\n",
       "  'Dist_hispanic_teachers': 16.5,\n",
       "  'Dist_white_teachers': 51.7,\n",
       "  'Hispanic_White_Achievement_Gap': -9.0,\n",
       "  'black_students': 22.9,\n",
       "  'hispanic_students': 28.3,\n",
       "  'school_county': 'COOK',\n",
       "  'school_district': 'CITY OF CHICAGO SD 299',\n",
       "  'school_name': 'YOUNG MAGNET HIGH SCHOOL',\n",
       "  'student_enrollment': 2114,\n",
       "  'white_students': 29.0},\n",
       " {'Black_Hispanic_Achievement_Gap': -5.0,\n",
       "  'Black_White_Achievement_Gap': -32.0,\n",
       "  'Dist_black_teachers': 4.0,\n",
       "  'Dist_hispanic_teachers': 3.7,\n",
       "  'Dist_white_teachers': 92.3,\n",
       "  'Hispanic_White_Achievement_Gap': -27.0,\n",
       "  'black_students': 27.9,\n",
       "  'hispanic_students': 40.8,\n",
       "  'school_county': 'LAKE',\n",
       "  'school_district': 'ZION-BENTON TWP HSD 126',\n",
       "  'school_name': 'ZION-BENTON TWNSHP HI SCH',\n",
       "  'student_enrollment': 2263,\n",
       "  'white_students': 24.0}]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell be used to view the last 5 schools scraped\n",
    "master_list_school_dictionaries[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling Data and formatting it for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable **master_list_school_dictionaries** contains dictionaries of all the schools.\n",
    "we can turn our data into a dataframe by turning the list of dictionaries into a dictionary of lists and then using the pandas module to convert it into a dataframe.\n",
    "The resulting dataframe will be pickled for future use.\n",
    "\n",
    "The way I wrote the code means that not all the dictionaries have all of the values. For example if there were not enough Black students at a school, there isn't a value for Black-Hispanic or Black-White Achievement Gap. The **check_for_keys()** function will look at each school dictionary individually from the master_list_school_dictionaries and add the missing keys with values of np.NaN in place of actual values. These can be imputed later if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "All_keys = ['Black_Hispanic_Achievement_Gap',\n",
    "  'Black_White_Achievement_Gap',\n",
    "  'Dist_black_teachers',\n",
    "  'Dist_hispanic_teachers',\n",
    "  'Dist_white_teachers',\n",
    "  'Hispanic_White_Achievement_Gap',\n",
    "  'black_students',\n",
    "  'hispanic_students',\n",
    "  'school_county',\n",
    "  'school_district',\n",
    "  'school_name',\n",
    "  'student_enrollment',\n",
    "  'white_students']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_for_keys(dict_to_check,list_of_keys):\n",
    "    \"\"\"\n",
    "    checks a dictionary to makes sure it has specified keys.\n",
    "    If it doesn't it will create a new key with a value of np.NaN\n",
    "    Returns the modified dictionary\n",
    "    \"\"\"\n",
    "    for key_of_interest in list_of_keys:\n",
    "        if key_of_interest not in dict_to_check.keys():\n",
    "            dict_to_check[key_of_interest] = np.NaN\n",
    "    return dict_to_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_of_dicts_to_dict_of_lists(list_of_dicts):\n",
    "    \"\"\"\n",
    "    Turns a list of dictionaries with common keys into one dictionary containing\n",
    "    a list of values for each key. This makes it easy to create a dataframe object.\n",
    "    Dictionaries with missing keys are handled by the check_for_keys function\n",
    "    Returns a Dictionary of Lists.\n",
    "    \"\"\"\n",
    "    dict_of_lists = collections.defaultdict(list)\n",
    "    for index,dictionary in enumerate(list_of_dicts,1):\n",
    "        dictionary = check_for_keys(dictionary,All_keys)\n",
    "        for key, value in dictionary.items():\n",
    "            dict_of_lists[key].append(value)\n",
    "        if index % 25 == 0:\n",
    "            print(f\"{index} / {len(list_of_dicts)} completed\")\n",
    "    print(f\"All {len(list_of_dicts)} schools converted\")\n",
    "    return dict_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master_list_school_dictionaries is a <class 'list'>\n",
      "25 / 236 completed\n",
      "50 / 236 completed\n",
      "75 / 236 completed\n",
      "100 / 236 completed\n",
      "125 / 236 completed\n",
      "150 / 236 completed\n",
      "175 / 236 completed\n",
      "200 / 236 completed\n",
      "225 / 236 completed\n",
      "All 236 schools converted\n",
      "student_data_df is a <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"master_list_school_dictionaries is a\",type(master_list_school_dictionaries))\n",
    "pre_df_student_data = list_of_dicts_to_dict_of_lists(master_list_school_dictionaries)\n",
    "student_data_df = pd.DataFrame(pre_df_student_data)\n",
    "print(\"student_data_df is a\",type(student_data_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling the DataFrame to filename:\n",
    "**student_data_df_pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Black_Hispanic_Achievement_Gap</th>\n",
       "      <th>Black_White_Achievement_Gap</th>\n",
       "      <th>Dist_black_teachers</th>\n",
       "      <th>Dist_hispanic_teachers</th>\n",
       "      <th>Dist_white_teachers</th>\n",
       "      <th>Hispanic_White_Achievement_Gap</th>\n",
       "      <th>black_students</th>\n",
       "      <th>hispanic_students</th>\n",
       "      <th>school_county</th>\n",
       "      <th>school_district</th>\n",
       "      <th>school_name</th>\n",
       "      <th>student_enrollment</th>\n",
       "      <th>white_students</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-12.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>89.9</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>COOK</td>\n",
       "      <td>CHSD 218</td>\n",
       "      <td>A B SHEPARD HIGH SCH (CAMPUS)</td>\n",
       "      <td>1723</td>\n",
       "      <td>49.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>87.2</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>61.7</td>\n",
       "      <td>DUPAGE</td>\n",
       "      <td>DUPAGE HSD 88</td>\n",
       "      <td>ADDISON TRAIL HIGH SCHOOL</td>\n",
       "      <td>2005</td>\n",
       "      <td>30.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-22.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.8</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>LAKE</td>\n",
       "      <td>ADLAI E STEVENSON HSD 125</td>\n",
       "      <td>ADLAI E STEVENSON HIGH SCHOOL</td>\n",
       "      <td>4027</td>\n",
       "      <td>60.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-31.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>92.3</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>MADISON</td>\n",
       "      <td>ALTON CUSD 11</td>\n",
       "      <td>ALTON HIGH SCHOOL</td>\n",
       "      <td>2008</td>\n",
       "      <td>63.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>98.1</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15.7</td>\n",
       "      <td>COOK</td>\n",
       "      <td>CONS HSD 230</td>\n",
       "      <td>AMOS ALONZO STAGG HIGH SCHOOL</td>\n",
       "      <td>2286</td>\n",
       "      <td>75.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Black_Hispanic_Achievement_Gap  Black_White_Achievement_Gap  \\\n",
       "0                           -12.0                        -29.0   \n",
       "1                             NaN                          NaN   \n",
       "2                           -22.0                        -51.0   \n",
       "3                           -31.0                        -19.0   \n",
       "4                            -5.0                        -27.0   \n",
       "\n",
       "   Dist_black_teachers  Dist_hispanic_teachers  Dist_white_teachers  \\\n",
       "0                  3.6                     5.5                 89.9   \n",
       "1                  1.6                     7.3                 87.2   \n",
       "2                  0.9                     0.0                 94.8   \n",
       "3                  4.8                     0.2                 92.3   \n",
       "4                  0.4                     0.8                 98.1   \n",
       "\n",
       "   Hispanic_White_Achievement_Gap  black_students  hispanic_students  \\\n",
       "0                           -17.0            24.3               23.0   \n",
       "1                           -34.0             2.2               61.7   \n",
       "2                           -29.0             1.9                7.3   \n",
       "3                           -13.0            25.0                2.4   \n",
       "4                           -22.0             4.3               15.7   \n",
       "\n",
       "  school_county            school_district                    school_name  \\\n",
       "0          COOK                   CHSD 218  A B SHEPARD HIGH SCH (CAMPUS)   \n",
       "1        DUPAGE              DUPAGE HSD 88      ADDISON TRAIL HIGH SCHOOL   \n",
       "2          LAKE  ADLAI E STEVENSON HSD 125  ADLAI E STEVENSON HIGH SCHOOL   \n",
       "3       MADISON              ALTON CUSD 11              ALTON HIGH SCHOOL   \n",
       "4          COOK               CONS HSD 230  AMOS ALONZO STAGG HIGH SCHOOL   \n",
       "\n",
       "   student_enrollment  white_students  \n",
       "0                1723            49.3  \n",
       "1                2005            30.4  \n",
       "2                4027            60.3  \n",
       "3                2008            63.6  \n",
       "4                2286            75.3  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The code below can pickle the dataframe once it is created\n",
    "``` python\n",
    "pd.to_pickle(student_data_df,'../../temp_files_projects/student_data_df.pkl')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
